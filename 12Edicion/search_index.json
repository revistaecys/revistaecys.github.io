[["index.html", "Doceava Edición - El tesoro enigmático Maya Enlaces disponibles", " Doceava Edición - El tesoro enigmático Maya Escuela de Ingeniería en Ciencias y Sistemas - ECYS 2018-03-01 Enlaces disponibles Revista Ciencias, Sistemas y Tecnología. Facultad de Ingenieria Escuela de Ingeniería en Ciencias y Sistemas Revista Ciencias, Sistemas y Tecnología - Issuu.com "],["00-editorial.html", "Editorial Director General Coordinación Editorial Portada, redacción, diseño y diagramación Contactenos", " Editorial Guatemala está avanzando en la transformación digital, tanto el sector privado como las instituciones públicas están trabajando fuertemente para aprovechar los avances en la tecnología de la información y la comunicación. Plataformas tecnológicas como las proporcionadas por Netlix, Coursera, Uber, Airbnb y Uber Eats entre otras, están transformando la forma en que se hacen negocios, la educación, el entretenimiento y, hasta cierto punto, nuestra cultura. En el ámbito de las instituciones públicas, la Superintendencia de Administración Tributaria, SAT, está impulsando el nuevo régimen de Factura Electrónica (FEL) que impulsa una tributación en línea y en tiempo real. Esto abre un enorme mercado de oportunidades para crear nuevos productos y servicios, habilitar nuevas plataformas y transformar rápidamente nuestro país. La gestión de la nube como plataforma de implementación, junto al desarrollo de Arquitecturas Orientadas a Servicios para conectar los sistemas legados, nuevas plataformas construidas con Microservicios, Contenedores, DevOps y Colas de mensajes serán cada vez más importantes y más demandadas, al mismo tiempo que el software libre toma mayor protagonismo en estos nuevos desarrollos. El dominio y conocimiento de las tecnologías que sustentan los nuevos modelos de desarrollo como XML, servicios web, servicios rest y manejo complejo de eventos se convierten en competencias indispensables para desarrollar los cambios tecnológicos que mantendrán a las organizaciones públicas y privadas al ritmo de la tecnología. El uso de tecnologías de seguridad de la información como firmas digitales avanzadas se hacen indispensables conjuntamente con el conocimiento subyacente como la criptografía y los estándares para generación de identificadores únicos, se están convirtiendo rápidamente en necesidades altamente urgentes tanto para el sector privado como para el sector público. Los grandes retos que supone el cambio climático hacen indispensable que la gestión de recursos naturales del país pueda ser eficiente y en tiempo real, tecnologías de simulación, sistemas de información geográficos, manejo de Sensores, Internet de las Cosas y gestión de imágenes satelitales se vuelven cada vez más necesarias en este sentido. El mercado de trabajo cambia rápidamente, las competencias y conocimientos técnicos y científicos se hacen cada vez más importantes y complejos, por lo que en nuestro rol de Ingenieros en Ciencias y Sistemas tenemos el gran reto de obtener las competencias y conocimientos necesarios para explotar y aprovechar la coyuntura tecnológica por la que atraviesa el país en estos momentos. En esta edición de la revista digital de la Escuela de Ingeniería en Ciencias y Sistemas se abordan temas relacionados al desarrollo de software, tecnología Lidar, Criptografía, análisis de la información e Inteligencia Artificial, con el afán de motivar en sus lectores la curiosidad por ahondar y experimentar con las nuevas tecnologías de la información y la comunicación. Ing. Marlon Pérez Türk Director de la Escuela de Ciencias y Sistemas Facultad de Ingeniería Universidad de San Carlos de Guatemala Director General         Ing. Marlon Pérez Türk Coordinación Editorial         Ing. Álvaro Giovanni Longo Morales Portada, redacción, diseño y diagramación         Ing. Álvaro Giovanni Longo Morales Contactenos         revista.ecys@gmail.com "],["00-contenido.html", "Contenido", " Contenido 01 Ciberseguridad en Guatemala 02 Polymer: Desbloqueando el potencial de la plataforma web 03 La sorprendente tecnología LIDAR 04 Herramientas de un Hacker Ético para combatir vulnerabilidades 05 El tesoro enigmático Maya 06 Análisis de información pública con herramienta estadística R 07 Inteligencia artificial Alpha Zero 08 FOG Computing 09 Amazon Alexa y su conquista del mercado de los asistentes inteligentes "],["01-jvelasquez.html", "Ciberseguridad en Guatemala Conclusiones Referencias", " Ciberseguridad en Guatemala José Alberto Velasquez Orozco josevelasquez3064@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: Tecnología, Seguridad, Informática, Guatemala. Imagen 1: Mensaje aparecido en algunos ordenadores de Telefónica tras el ataque Fuente: El Economista Hace poco menos de un año fue conocido un ataque que afectó a más de 600 empresas a nivel mundial, pero fue especialmente conocida porque una de esas empresas fue la multinacional telefónica con sede principal en España. Este tipo de ataque conocido como Ransomware consiste en citar y evitar el acceso a documentos, videos, fotos, audios, bases de datos y pedir un pago (Dólares, Euros, Monedas Virtuales como el bitcon). Al conocer de esto inmediatamente empresas que no habían sido afectadas activaron sus protocolos de seguridad para evitar así el contagio y la posterior extorsión fue tanta la prudencia que algunas empresas ordenaron a sus trabajadores apagar todo el equipo utiizado inmediatamente. Aunque ciertamente una gran cantidad de empresas tienen protocolos de seguridad no siempre son del todo efectivos tales baches de seguridad son aprovechados por los malhechores para cometer sus ilícitos Dentro de estas fallas podemos encontrar dos que son muy recurrentes: Sistemas desactualizados: El tener un sistema desactualizado no debe ser opción, frecuentemente los desarolladores de los sistemas operativos deben realizar parches o actualizaciones de seguridad para corregir errores o vulnerabilidades encontradas, sin embargo estos parches de nada sirven si las empresas no actualizan su equipo. Archivos adjuntos en Correo Electrónico y/o Redes Sociales: Está falla es la más común, debido a la ingenuidad y/o curiosidad de algunos usuarios/empleados que abren correos de contactos desconocidos o incluso contactos conocidos que ya fueron infectados. Algunas empresas dentro de sus políticas poseen actualizaciones a cada cierto tiempo y bloqueos a redes sociales, correos personales ya que a través de estos es más probable que se susciten dichos acontecimientos, además se debe concientizar a los empleados a tener precaución en los archivos de dudosa procedencia, evitar abrirlos, responderlos y denunciarlos ante el departamento encargado. Una alternativa prudente que las empresas deberían considerar para el acceso a sus datos es el uso de VPN, ya que estas les brindan una capa adicional de seguridad (esto en el caso de que se necesite acceso a la red de la empresa desde el exterior, además de brindar confidencialidad a los usuarios, integridad en la transferencia de datos, entre otros. La única desventaja del acceso VPN es que la mayoría es de paga. Pero ¿Qué se debe hacer si ya ha sido infectado? Lo primero que es importante mencionar es que inmediatamente después de la infección está se hará visible a través del no acceso a sus datos y un mensaje en pantalla solicitando un pago para poder liberarlos. Aún si la empresa tuviera la capacidad de pago, lo más recomendable es no hacerlo, ya que nada garantiza que una vez hecho el pago los archivos se liberen, y si los liberan es muy probable que secuestren los archivos de nuevo debido a que los atacantes saben que las empresas harán los pagos necesarios. En países más desarollados existen instituciones encargadas de velar por la seguridad de la información de sus instituciones, sin embargo en Guatemala el tema de la Ciberseguridad aún se encuentra retrasado, siendo el principal factor el hecho que las instituciones encargadas no le han dado el valor correspondiente a los delitos informáticos. Imagen 2: Expertos en ciberseguridad piden esfuerzo sin fisuras contra injerencia rusa Fuente: Diario de Centro América En el año 2017 se desarrolló durante tres días en la ciudad de Antigua Guatemala reuniones de trabajo para crear el primer borrador de la Estrategia Nacional de Ciberseguridad dirigida por el ministerio de Gobernación con el apoyo de la Unión Europea y la Organización de Estados Americanos (OEA). Dicha Estrategia tiene como principal objetivo proteger las Bancas Virtuales, páginas de los diferentes Ministerios del Gobierno, Organizaciones Sociales y entidades Privadas. Según indicó Walter Girón viceministro de Tecnología de la Comunicación es esta estrategia  Guatemala debe resguardar sus archivos privados con una seguridad altamente potencial para evitar ser afectado por hackers. Por su parte Manuel de Almeida, jefe del Programa del Cibercrimen en la Comunidad Europea indico Guatemala, está haciéndolo de la manera más correcta porque al tener la legislación otras herramientas pueden surgir como un laboratorio forense para estudiar las pruebas electrónicas. Es importante para paises en vías de desarollo como Guatemala dar sus primeros pasos en la creación una legislación para este tipo de delos para lograr una capacidad de respuesta válida, correcta y sobre todo eficiente, además por supuesto de los recursos técnicos y recursos humanos capacitados. Imagen 3: El sector financiero afianza la ciberseguridad Fuente: El Periódico Conclusiones Las empresas e instituciones deben tener una politica de acceso a sus datos, ademas de una cultura de cuidado en redes sociales y correo electronico. Las empresas y gobierno guatemalteco deben encontrar politicas de reaccién a ataques informaticos ademas de legislar, juzgar delitos criminales. Referencias [1] Laura de la Quintana, «El Economista», El ataque informático mundial afectó hasta a 600 empresas españolas, 15 mayo 2017. [En línea]. Disponible en: https://bit.ly/3gRoSr5. [Último acceso: 14 febrero 2018]. [2] Chema Flores, «El Economista», Cómo evitar un ataque de ransomware y qué hacer si se está sufriendo uno, 12 mayo 2017. [En línea]. Disponible en: https://bit.ly/2SVVyYH. [Último acceso: 14 febrero 2018]. [3] «Certsi», Respuesta a incidentes, 01 octubre 2018. [En línea]. Disponible en: https://bit.ly/3wR1qRF. [Último acceso: 14 febrero 2018]. [4] «Le VPN», ¿Cómo Puedo Hacer Mi VPN Aún Más Segura?, 05 julio 2016 [En línea]. Disponible en: https://bit.ly/3vYIBed. [Último acceso: 14 febrero 2018]. [5] «Prensa Libre», Guatemala trabaja estrategia nacional de ciberseguridad, 24 enero 2017 [En línea]. Disponible en: https://bit.ly/3h9PwLW. [Último acceso: 14 febrero 2018]. [6] «IGF Guatemala», Ciberseguridad Foro de IGF Guatemala 2017, 20 julio 2017 [En línea]. Disponible en: https://bit.ly/3h30R1B. [Último acceso: 14 febrero 2018]. [7] «Ministerio de Gobernación de Guatemala», Crearán borrador para propuesta de ley para el combate al Cibercrimen, 13 febrero 2017 [En línea]. Disponible en: https://bit.ly/3dsoz58. [Último acceso: 14 febrero 2018]. "],["02-crodriguez.html", "Polymer: Desbloqueando el potencial de la plataforma web Conclusiones Referencias", " Polymer: Desbloqueando el potencial de la plataforma web Carlos Estuardo Gómez Rodríguez carlos001909@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: Aplicaciones web, Polymer, componentes web, Alto rendimiento, #UseThePlatform, experiencia de usuario. Desarrollar una aplicación web es un reto para cualquier programador. Desde la aspecto visual que tendrá, hasta la experiencia final de los usuarios al navegar por toda la aplicación web. Estos son algunos de los aspectos que como programador nos planteamos antes de aventurarnos en la ardua tarea de codificar y de plasmar todas esas ideas que invaden nuestra mente, y entre todas estas interrogantes surge una de las más enigmáticas y difíciles de responder, ¿Qué herramientas, frameworks, bibliotecas, etc. debería de utilizar para construir mi aplicación web? Dado un mar de posibles respuestas surge una y es acá donde Polymer sale del anonimato y cobra protagonismo. Pero ¿Qué o quién es Polymer? Imagen 1: Polymer Project Logo Fuente: Polymer Project Desbloquee el poder de los componentes web es la frase con la que Polymer hace su aparición. Polymer no es más que una biblioteca liviana de JavaScript desarrollada por Google de código abierto orientada a la creación de componentes web que son fáciles de crear y que pueden ser reutilizables. El proyecto que dio sus primeros pasos en el 2013 ha avanzado a lo largo de los últimos años evolucionando constantemente siendo la versión 2 la más reciente de esta biblioteca, anunciándose desde ya la versión 3 para este año. Esta biblioteca bajo el lema #UseThePlatform hace propuestas interesantes, afirmando que los usuarios merecen aplicaciones rápidas, fluidas y que puedan acceder desde cualquier lugar con cualquier dispositivo de cualquier tamaño a las aplicaciones y que por otro lado, los desarrolladores merecen una plataforma que facilite: la creación, el mantenimiento, la confiabilidad y el alto rendimiento. Tal como lo define el equipo de Polymer #UseThePlatform se trata de promover el uso de la plataforma web para ofrecer las mejores aplicaciones posibles y ayudar a garantizar que los usuarios y desarrolladores web obtengan todo lo que se merecen de la plataforma en el futuro. Polymer orienta la creación de aplicaciones web haciendo uso de componentes web. Un componente de Polymer se compone de tres partes: la primera es la visual del componente desarrollada en HTML, la segunda que es el CSS encargado del estilo y la tercera que es la parte de JavaScript que nos permite interactuar tanto con el HTML como con el CSS. Polymer posee una gran comunidad que realiza aportes de conocimiento así como publicación de elementos para que puedan ser utilizados por terceros. De igual forma existen elementos que son creados por el equipo de desarrollo de Polymer. Estos elementos nos permiten agregar funcionalidades increíbles a nuestra aplicación web, siendo fáciles de utilizar. Google utiliza esta biblioteca en algunos de sus servicios y sitios web, tal es el caso de Youtube, Google Play Music, Google sites. Según el sitio oficial de Polymer empresas como BBVA, Coca Cola, COMCAST están utilizando esta solución. Ahora que sabemos que es Polymer, la pregunta a contestar es ¿Por que utilizar Polymer? Esto desencadena un listado de respuestas siendo las principales ventajas y características: Aplicaciones web desde otra perspectiva. La utilización de componentes web para la creación de aplicaciones web nos facilitará la mantenibilidad de dicha aplicación y permitirá la reutilización de los mismos para otras aplicaciones. Aplicaciones rápidas. Polymer nos permite desarrollar aplicaciones rápidas de alto rendimiento y brindar experiencias de usuario increíbles. Los elementos de Polymer siguen las líneas de diseño de Material Design. Material Design es un concepto de diseño creado por Google enfocado a una experiencia unificada para todas las plataformas y tamaños de dispositivos. Con esto no debemos de preocuparnos por aspectos visuales o gráficos, siempre que sigamos las normas de Material Design se verá impecable. Utilización de APIs de Google. El poder utilizar todo el potencial del sin fin de APIs que Google proporciona dentro de Polymer es asombroso, sin mencionar que existen algunos componentes web que hacen aún más fácil la utilización de dichas APIs. Una comunidad numerosa. Los aportes que la comunidad de Polymer hace sumado a eso la documentación que existe por parte de Google, hacen que programar en Polymer sea placentero. Compatibilidad con los principales navegadores. Google Chrome, Firefox, Opera y Safari se unen a la lista de navegadores que exitosamente ejecutarán Polymer sin ningún problema. Google un gran aliado. Saber que Google está detrás del desarrollo de todo esto y que aparte de ello lo utiliza para algunas de sus aplicaciones web tales como Youtube, nos conforta y da seguridad para iniciar con esta alternativa. Imagen 2: Material Design Fuente: Google Apis Conclusiones Crear experiencias de usuario impactantes, es uno de los retos a los que se enfrenta un desarrollador de aplicaciones web y que sin duda Polymer se convierte en un aliado valioso para superar dicho reto. Crear aplicaciones web mantenibles, de acceso universal y alto rendimiento, son factores importantes que todo desarrollador debe tener en mente y cumplirlas a cabalidad. Referencias [1] «Polymer Project», Polymer 2.0, 08 marzo 2017. [En línea]. Disponible en: https://bit.ly/3rSizqR. [Último acceso: 14 febrero 2018]. [2] «Polymer Project», Our Mission, 08 marzo 2017. [En línea]. Disponible en: https://bit.ly/3mrZZF2. [Último acceso: 14 febrero 2018]. [3] «Polymer Project», Whos using Polymer, 07 enero 2018. [En línea]. Disponible en: https://bit.ly/39H2uy1. [Último acceso: 14 febrero 2018]. [4] «Material», Material Design, 01 abril 2015. [En línea]. Disponible en: https://bit.ly/3fLHF8n. [Último acceso: 14 febrero 2018]. "],["03-bcardona.html", "La sorprendente tecnología LIDAR Recepción de láseres LIDAR ¿Qué es una nube de punto? Conclusiones Referencias", " La sorprendente tecnología LIDAR Berny Andreé Cardona Ramos andreecr96@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: LIDAR, nube de puntos, teledetección, sensor, laser. El LIDAR (de light detection and ranging) es una técnica de teledetección óptica que utiliza la luz de láser para obtener una muestra densa de la superficie de la tierra produciendo mediciones exactas de X, Y y X. es un sensor óptico activo que transmite rayos láser hacia un objetivo mientras se mueve a través de rutas de topografía específicas. El reflejo del láser del objetivo lo detectan y analizan los receptores en el sensor LIDAR. Estos receptores registran el tiempo preciso desde que el pulso láser dejó el sistema hasta cuando regresó para calcular la distancia límite entre el sensor y el objetivo. Combinado con la información posicional (GPS e INS), estas medidas de distancia se transforman en medidas de puntos tridimensionales reales del objetivo reflector en el espacio del objeto. Imagen 2: Funcionamiento del sensor óptico activo LIDAR Fuente: Arcgis Recepción de láseres LIDAR Los pulsos láser emitidos desde un sistema LIDAR se reflejan desde objetos sobre y por encima de la superficie del suelo: vegetación, edificios, puentes y así sucesivamente. Un pulso láser emitido puede regresar al sensor LIDAR como uno o muchas devoluciones. Cualquier pulso láser emitido que encuentre varias superficies de reflejo a medida que viaja hacia el suelo se divide en tantas devoluciones como superficies reflectoras existen. Varias devoluciones pueden detectar las elevaciones de varios objetos dentro de la huella láser de un pulso láser saliente. Las devoluciones intermedias, en general, se utilizan para la estructura de la vegetación, y la última devolución para los modelos de terreno de suelo desnudo. La última devolución no siempre será de una devolución del suelo. Por ejemplo, considere un caso en donde un pulso golpee una rama gruesa en su camino hacia el suelo y el pulso no llega en realidad al suelo. En este caso, la última devolución no es desde el suelo, pero sino desde la rama que reflejó el pulso láser completo. ¿Qué es una nube de punto? Las nubes de punto inicial son grandes colecciones de puntos de elevación 3D, que incluyen x, y, z, junto con atributos adicionales como marcas de tiempo GPS. Las entidades de superficie específicas que el láser encuentra se clasifican después de que la nube de punto LIDAR inicial es postprocesada. Imagen 1: Modelo Digital del Terreno construido mediante fotogrametría Fuente: Wikipedia Conclusiones Con un LIDAR se puede conocer en tiempo real la posición precisa de millones de puntos, y la distancia entre cada punto y el foco del LIDAR. Con el sistema LIDAR se puede transformar de un vehículo normal a un vehículo autónomo en base a la nube de puntos generados y recibidos de su entorno. LIDAR es fundamental para que la conducción inteligente sea más eficiente. Referencias [1] «Arcgis», What is LIDAR data?, 2017. [En línea]. Disponible en: https://bit.ly/3fH33LT. [Último acceso: 14 febrero 2018]. [2] «Motorpasion», Qué es un Lidar y como funciona el sensor mas caro en los coches autónomos, 28 septiembre 2017. [En línea]. Disponible en: https://bit.ly/3ukiFco. [Último acceso: 14 febrero 2018]. "],["04-jgiron.html", "Herramientas de un Hacker Ético para combatir vulnerabilidades Conclusiones Referencias", " Herramientas de un Hacker Ético para combatir vulnerabilidades José Antonio Girón Tager josegt10100@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: Hacker, Hacking ético, Herramientas, Ingeniería social, Software, Seguridad, Vulnerabilidad. Según el ingeniero Juan P. Baby Fernández no solamente se debe enfocar el hacker ético en la seguridad lógica de la empresa, sino que también lo que es la seguridad física. La ingeniería social es una de las herramientas que cualquier individuo puede realizar desde fuera de la empresa con fin de robar información de la empresa o hasta en casos extremos lo que es el hardware como cualquier otro ladrón. Como podemos ver en la imagen 1, esto se basa en ubicar a personas vulnerables dentro de una empresa y saber manejar los hilos para alcanzar el objetivo. Por esto, una de las herramientas más simples que tiene un hacker ético es la ingeniería social debido a que localiza las fisuras físicas no importando cuanta seguridad lógica haya dentro de la empresa. Existe software que automatiza estos ataques desde mensajes de texto falsos hasta clonar una web y es Social Engineering Toolkit (SET). Además, existen herramientas que no requieren de ingeniería social para hackear, sino que estas aplicaciones realizan operaciones con las que tratan de buscar vulnerabilidades; entre ellas podemos encontrar las más usadas por la comunidad informática que son: Ettercap, Burp Suite, Aircrack-NG, NMAP, Nessus, Wireshark, Metasploit, John The Ripper y THC Hydra (imagen 2). Empezando por Ettercap, esta herramienta sirve para realizar ataques conocidos como man in the middle porque envenena las tablas ARP con las cuales logra redirigir el tráfico de un sitio web a otro sitio falso, a esto se le es llamado como DNS poofing. Las demás aplicaciones mencionadas sirven para detectar vulnerabilidades y realizar ataques de fuerza bruta. En cuanto a la detección de vulnerabilidades se tiene Burp Suite, la cual lo logra interceptando datos y peticiones entre el servidor y un navegador; NMAP, que sirve para la detección de dispositivos en la red donde se puede identificar los puertos abiertos y los servicios que están corriendo; Nessus y Metasploit, que puede hacer uso de NMAP o su propio Scanner para detectar vulnerabilidades utilizando exploits considerándolas como llaves de acceso; por ultimo tenemos Wireshark y Aircrack-NG, estas herramientas sirven para capturar en Aircrack-NG el tráfico de las redesinalámbricas y en Wireshark, el tráfico en tiempo real analizando los protocolos de conexión. Hablando ahora sobre los ataques de fuerza bruta se utilizan Aircrack-NG, donde por medio de ataques de este tipo se puede determinar la contraseña de un modem y romper el cifrado web; John The Ripper, utilizando este ataque basado en diccionarios es capaz de romper contraseñas y THC Hydra, que está especializada en emplear protocolos de red como protocolos de correo, bases de datos, LDAP, SMB, VNC y SSH para acceder remotamente a sistemas. Estas herramientas expuestas nos sirven para combatir brechas en la seguridad, prevenir el acceso de criminales y poder tomar medidas preventivas para defenderse. Imagen 1: Hackers Fuente: Gary Markstein Conclusiones La evolución de la tecnología ha proporcionado una brecha de inseguridad en los sistemas de los gobiernos como las empresas y para combatir esto se empezaron a hacer auditorias las cuales las lleva a cabo un hacker ético. Los dos tipos de herramientas que un hacker ético necesita para poder determinar las vulnerabilidades o fisuras de un sistema son las que sirven para la detección en la seguridad física y lógica. Existen varias aplicaciones que ayudan a un hacker ético en plan de probar la seguridad de un sistema como: SET, Ettercap, Burp Suite, Aircrack-NG, NMAP, Nessus, Wireshark, Metasploit, John The Ripper y THC Hydra. Referencias [1] Manuel Henry Sánchez Carvajal, «Revista de Información, Tecnología y Sociedad», Ethical Hacking: La importancia de una intrusión controlada, julio 2013. [En línea]. Disponible en: https://bit.ly/3t3uG5C. [Último acceso: 14 febrero 2018]. [2] Juan P. Baby Fernández, «FUNGLODE», El Hacker: Tácticas y Herramientas, 09 marzo 2019. [En línea]. Disponible en: https://bit.ly/2QWtRNV. [Último acceso: 14 febrero 2018]. [3] «OHCS», Top 10 Herramientas de Hacking, 21 julio 2017. [En línea]. Disponible en: https://bit.ly/3sQ938R. [Último acceso: 14 febrero 2018]. [4] Rubén Velasco,«Redes Zone», Las mejores herramientas de Hacking para este 2017, 06 enero 2017. [En línea]. Disponible en: https://bit.ly/2R6brdQ. [Último acceso: 14 febrero 2018]. "],["05-jsazo.html", "El tesoro enigmático Maya ¿Cómo se tiene conocimiento de la riqueza que poseía la civilización Maya?. ¿A qué tesoro me refiero? Conclusiones Referencias", " El tesoro enigmático Maya Jherson Sazo jhersonaos7@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: Ciencia, tecnología, civilización, matemática, maya, IT, Guatemala, Silicon Valley. Imagen 1: Ciencia y Tecnología Maya Fuente: Camaleo Si regresáramos en el tiempo, en la época de la civilización maya, cuando aún no se conocía el término Maya, y analizáramos detalladamente el conocimiento que poseían, su ciencia, tecnología, matemáticas, medicina podríamos ver la riqueza intelectual que poseían, así aceptaríamos con más certeza el termino por el cual se les ha considerado los griegos de la América prehispánica, ya que a los mayas se les considera como una parte de los mejores astrónomos de la historia, lograron definir el paso del sol solo con palo perpendicular, algo que es sorprende es que los Mayas calcularon la rotación completa de la tierra, con diferencia de 0.0002 días, respecto al de la NASA y , fueron capaces de predecir el eclipse total del sol que se produjo en agosto de 1999. No se puede hablar de astronomía maya sin tomar en cuenta, su sistema matemático maya, que fue destacado ante a las demás civilizaciones de esa era, puesto que este sistema tomaba en cuenta el número 0 (siglo I a.C, fecha del primer registro del número 0), en medicina, estudiaron la etiología de las enfermedades para prevenirlas y encontrarles cura, incluso utilizaban yeso para las fracturas, y así podríamos seguir hablando de aspectos sobresalientes de esta civilización, pero surge la pregunta: ¿Cómo se tiene conocimiento de la riqueza que poseía la civilización Maya?. Este conocimiento se debe al descubrimiento de Guatemala posterior al descubrimiento de América por Cristóbal Colon en 1542, es entonces que se puede hacer énfasis en la palabra descubrimiento, la civilización maya se dio a conocer debido a esto, pero ¿Guatemala es conocida a nivel mundial en la actualidad?, según estadísticas en el año 2017, 2.1 millones de personas visitaron nuestro país en el término turístico, los turistas conocen nuestros hermosos lugares turisticos como Tikal, Panajachel, Antigua Guatemala, Semuc Champey, algunos los volcanes y montañas, áreas protegidas, etc. Pero ¿en el término de tecnología e información? Se me viene a la mente un dicho muy popular que dice Si fuera culebra me pica, porque yace en Guatemala un tesoro que aún no se ha descubierto en su totalidad: ¿A qué tesoro me refiero? En alguna sino es que en muchas veces se han encontrado en internet con molestas letras un poco difíciles de entender para confirmar alguna transacción o registro, esa pequeña creación fue hecha por el guatemalteco Luis von Ahn, informático que actualmente labora en la Universidad de Carnegie Mellon, un pequeño CAPTCHA que se utiliza globalmente, un pequeño aporte en tecnología para el mundo. En estos tesoros intelectuales podemos mencionar a Deiby Gómez, el profesional más joven hasta el momento en obtener el título de Oracle ACE Director y la certificación de Oracle Certified Master 12c, Edward Hirst, ingeniero Aeroespacial, quien tuvo cargo el proyecto Juno de la NASA, el cual buscaba que una aeronave llegará a Júpiter, y así puede hacerse referencia a muchos profesionales sobresalientes de Guatemala. Si la tecnología fuera un mundo, nuestro país de la hermosa primavera no aparecería en el mapa, y no se debe a que no posea sino que muchas veces por las pocas oportunidades que se tienen para dar a conocer el potencial que se posee en materia prima tecnológica, podemos mencionar que en el sector de IT y Digital hubo un crecimiento de 8% en 2015, actualmente se está trabajando en el fortalecimiento de este sector, que apunta al desarrollo de nuestro país, tal es el caso del proyecto del SILICON VALLEY en Guatemala que desarrolla un área en el Campus Tec con la coordinadora de desarrollo de negocios Magister Maria Zaghi, que comparte similitudes con los emprendimientos de la conocida ciudad tecnológica estadounidense. Guatemala tiene talento, calidad, capacidad, efectividad, para poder exportar IT, como Adrián Catalán primer guatemalteco en convertirse en Desarrollador Experto de Google, o Itzdata un grupo de Ingenieros guatemaltecos que exportan su conocimiento automatizando infraestructuras de nube escalables usando un enfoque DevOps. imagen 2 Como profesionales y/o estudiantes es nuestro deber trabajar arduamente para dar a conocer el talento que poseemos especialmente en el área de IT, participar en competiciones internacionales, optar por becas en el extranjero con el fin que se conozca el potencial que se tiene en nuestro país, laboral para el extranjero, como el ingeniero Sergio Flores, primer extranjero en la historia en laborar para Samsung Electronics, entre otros. Es así como podemos hacer que el mundo ponga su atención en Guatemala, necesitamos ser descubiertos como fue descubierta la Civilización maya, y darle a conocer al mundo nuestro tesoro enigmático que está aquí, ansioso de ser conocido, que está creciendo y perfeccionándose diariamente, y así poder exportar nuestro conocimiento al mundo. Imagen 2: El concurso Emprende con Cultura busca los mejores proyectos digitales relacionados con el sector Fuente: SOY502 Conclusiones El sector de IT está creciendo de forma exponencial en Guatemala, pero para traer mayor desarrollo a nuestro país necesita exportar su tecnología. Guatemala debe posicionarse como primer exportador de tecnología a nivel centroamericano para mejorar las ventajas competitivas que se posee nuestro país. Guatemala debe incidir para quitar el enigma que se tiene respecto a nuestra tecnología y así poder ser tomados en cuenta en proyectos de talla mundial. Referencias [1] «Sobre Historia», La ciencia de los Mayas: matemáticas, astronomía y medicina, 17 octubre 2016. [En línea]. Disponible en: https://bit.ly/3w4kASN. [Último acceso: 14 febrero 2018]. [2] «Sataffing América Latina», Guatemala: más competitiva y desarrollando talento para el sector de la TIC, 20 febrero 2018. [En línea]. Disponible en: https://bit.ly/36jdoYR. [Último acceso: 14 febrero 2018]. [3] «Campus Tecnológico Guatemala», Silicon Valley extiende sus fronteras y llega a Guatemala, 03 mayo 2015. [En línea]. Disponible en: https://bit.ly/3ygM5KB. [Último acceso: 14 febrero 2018]. "],["06-pecheverria.html", "Análisis de información pública con herramienta estadística R Conclusiones Referencias", " Análisis de información pública con herramienta estadística R Pablo Alejandro Echeverria Barrios pabechevb@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: Análisis, datos, estadística, validación, integridad, veracidad. El método elegido para validar que la información es real será si los datos se ajustan a un modelo predicho y si cumplen con la ley de Benford. Las herramientas a utilizar son de acceso gratuito y tienen el soporte de Microsoft: SQL Server Data Tools, SQL Server 2014 Express, R. El siguiente ejemplo corresponde a la base de datos del Banco de Guatemala, quien ha publicado datos sobre las exportaciones de las zonas francas en la siguiente dirección: Imagen 1: Comercio Exterior de Guatemala por inciso arancelario del SAC Fuente: Banco de Guatemala Los datos que se extraen corresponden a las exportaciones por país, producto y partida. El siguiente paso es cargar esta información a una base de datos que facilite la consulta, pero antes hay que darle formato a las columnas, ya que hay celdas que se encuentran unidas o no todas las celdas tienen valores, como se puede apreciar en las siguientes imágenes. Imagen 2: Exportaciones por país, producto y partida Fuente: Elaboración propia Al borrar filas, separar columnas y ajustar los datos con el uso de fórmulas de Excel, se genera un archivo que será fácil de cargar en la base de datos, como se puede apreciar en la siguiente imagen. Imagen 3: Resultado de la adecuación de los datos Fuente: Elaboración propia La carga de los datos se hace con la herramienta SQLServer Integration Services, creando los objetos de accesoal archivo de Excel (fuente) y a la base de datos (destino), y creandoel flujodetrabajoquenos permitacargar estainformación: Imagen 4: Carga de los datos con SQL Server Integration Services Fuente: Elaboración propia Una vez cargados los datos, se realiza una consulta que refleje los datos agrupados por mes, en lugar del detalle por partida, para ello se crea la consulta utilizando la herramienta SQL Server Management Studio: SELECT [Pais Comprador], [Producto], &#39;01Enero&#39; [Mes], SUM([Valor Enero]) [Valor], SUM([Volumen Enero]) [Volumen] FROM [Exportaciones]..[Exportaciones] GROUP BY [Pais Comprador], [Producto] UNION ALL  UNION ALL SELECT [Pais Comprador], [Producto], &#39;11Noviembre&#39; [Mes], SUM([Valor Noviembre]) [Valor], SUM([Volumen Noviembre]) [Volumen] FROM [Exportaciones]..[Exportaciones] GROUP BY [Pais Comprador], [Producto] ORDER BY 1, 2, 3 Se carga la información en la herramienta R para su análisis, considerando que se debió descargar el paquete RODBC que permite la conexión a la base de datos. &gt; install.packages(&quot;RODBC&quot;); &gt; library(RODBC); &gt; sqlcnn &lt;- odbcDriverConnect(Driver={SQL Server Native Client 11.0}; Server=localhost; Trusted_Connection=yes;); &gt; data &lt;- sqlQuery(sqlcnn, SELECT [Pais Comprador], [Producto], &#39;01Enero&#39; [Mes], SUM([Valor Enero]) [Valor], SUM([Volumen Enero]) [Volumen] FROM [Exportaciones]..[Exportaciones] GROUP BY [Pais Comprador], [Producto] UNION ALL  UNION ALL SELECT [Pais Comprador], [Producto], &#39;11Noviembre&#39; [Mes], SUM([Valor Noviembre]) [Valor], SUM([Volumen Noviembre]) [Volumen] FROM [Exportaciones]..[Exportaciones] GROUP BY [Pais Comprador], [Producto] ORDER BY 1, 2, 3); &gt; close(sqlcnn); Ahora con los datos cargados, la hipótesis a validar es que el valor depende del volumen de una forma lineal; es decir, si se encuentran datos que estén fuera del rango predicho, significaría que los datos no son reales. &gt; model &lt;- lm(Valor ~ Volumen, data); &gt; plot(data[,5:4]); &gt; abline(model, col=blue); Imagen 5: Validación de la hipótesis Fuente: Elaboración propia Como se observa, son muy pocos los datos que están fuera del rango, ya que para un volumen muy bajo, el valor a veces es un poco más alto, lo cual es perfectamente posible. Esto también podría depender del país hacia el cual se está exportando, que en algunos de ellos el precio sea más alto. Pero al tener visualmente la información tanto de los datos como del modelo que se espera que estos cumplan, no hay razones para sospechar que la información haya sido cambiada. Además se puede ver que la mayoría de los datos, tanto de volumen como de valor, empiezan con los dígitos 0 y 1; a medida que el primer dígito va cambiando, la cantidad de datos también va disminuyendo rápidamente, por lo que se cumple la ley de Benford. Conclusiones Utilizando la herramienta estadística R se demuestra que la información proveída es real y no ficticia. No hay razón para pensar que las exportaciones de zonas francas haya sido creada o manipulada, ya que los datos cumplen tanto con un modelo esperado como con la ley de Benford. Las técnicas de carga y análisis de la información se pueden emplear en cualquier base de datos de acceso público de las instituciones nacionales. Referencias [1] Ricardo Jauregui; Ferran Silva, «Universitat Politècnica de Catalunya», Numerical validation methods, 18 febrero 2018. [En línea]. Disponible en: https://bit.ly/3qFxl56. [Último acceso: 14 febrero 2018]. [2] «Data Integrity», Connecting to an XLSX using SSIS, 18 febrero 2018. [En línea]. Disponible en: https://bit.ly/3y6SgAA. [Último acceso: 14 febrero 2018]. [3] «CRAN», Package RODBC, 18 febrero 2018. [En línea]. Disponible en: https://bit.ly/3qEcHCr. [Último acceso: 14 febrero 2018]. [4] David Lillis, «The Analysis Factor», Linear Models in R: Plotting Regression Lines, 21 abril 2015. [En línea]. Disponible en: https://bit.ly/2R6brdQ. [Último acceso: 14 febrero 2018]. "],["07-wpalma.html", "Inteligencia artificial Alpha Zero Conclusiones Referencias", " Inteligencia artificial Alpha Zero Wilson Geovani Palma Pérez wilsonellolo@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: Inteligencia, ajedrez, IA, programa, artificial, autoaprendizaje. Para conocer y comprender mejor a Alpha Zero debemos conocer que es una inteligencia artificial, la inteligencia artificial simula la inteligencia humana por medio de máquinas las cuales en su mayoría suelen ser software, la inteligencia artificial incluye el aprendizaje y muchas veces el autoaprendizaje además del razonamiento y la capacidad de saber cuando han hecho algo mal para poder corregirlo en el futuro. La inteligencia artificial Alpha Zero creada por Deep Mind la cual es propiedad de Google, a diferencia de los demás software que funcionan como motores de ajedrez no está basado en conocimiento humano, por ejemplo Stockfish un software muy potente tiene una base de datos millonaria en conocimiento, dicho conocimiento es creación de humanos ya sea sobre partidas o libros teóricos sobre aperturas, medio tiempo y finales en ajedrez. Alpha zero va más allá del conocimiento y comprensión humana ya que lo que sabe sobre ajedrez es lo que el mismo deduce del juego, la única ayuda humana que recibió fue que se le enseñó las reglas del juego, a esto se le llama el autoaprendizaje. Tras jugar casi cinco millones de partidas durante cuatro horas contra sí mismo, Alpha Zero obtuvo el mismo conocimiento que los humanos en casi 1,400 años. Alpha Zero está basado en una red neuronal la cual es capaz de aprender a una gran velocidad y a límites desconocidos para los seres humanos, desde que las partidas de Alpha Zero contra Stockfish se hicieron públicas de cierta manera toda la teoría y conocimiento que se ha adquirido del ajedrez desde sus inicios pareciera cosa de niños ya que Alpha Zero hace movimientos que van en contra de los principios del ajedrez lo que supone que los principios del ajedrez están equivocados, por lo que se dice que Alpha Zero ha resuelto el ajedrez. Stockfish es el módulo de ajedrez más poderoso del mundo creado con el objetivo de hacer jugadas perfectas, el cual tiene la capacidad de calcular millones de jugadas y posiciones logrando así hacer siempre la jugada perfecta el unico inconveniente que tiene stockfish es que esta basado en conocimiento humano y apesar que es creado por ingenieros sumamente inteligentes, Alpha zero se basa en conocimiento propio el cual se puede decir que a llegado a alcanzar un nivel divino en el ajedrez. Alpha Zero al igual que muchas otras inteligencias artificiales serán capaces de cambiar el mundo ya que al ponernos a pensar, la IA de Google fue capaz de replicar e incluso superar siglos de conocimiento en unas cuantas horas. Conclusiones Las inteligencias artificiales serán capaces de resolver problemas que a los seres humanos nos tomaría cientos e incluso miles de años. Alpha Zero esla prueba que un algoritmo estructurado de manera perfecta es capaz de superar el alcance de su creador. La inteligencia artificial supera el entendimiento humano con lo que una máquina puede entender a un humano pero un humano no podría entender a una máquina. El ajedrez a pesar de que se ha resuelto seguirá siendo un deporte muy practicado y podemos ver la analogía con que aún se hacen competencias de correr a pesar de que hay motos que alcanzan velocidades a la que los humanos nunca llegaran. Referencias [1] Will Knight, «MIT Technology Review», Alpha Zero, la inteligencia artificial alienígena que domina tres juegos distintos, 15 diciembre 2017. [En línea]. Disponible en: https://bit.ly/3jyItzo. [Último acceso: 14 febrero 2018]. [2] Roberto Rodríguez, «La Vanguardia», Alpha Zero, el programa que revoluciona el ajedrez y puede cambiar el mundo, 14 diciembre 2017. [En línea]. Disponible en: https://bit.ly/3yhDd7z. [Último acceso: 14 febrero 2018]. "],["08-rsalvatierra.html", "FOG Computing ¿Qué es Fog Computing? Que sucede del lado de Fog Computing Que sucede en la nube Los beneficios que ofrece Conclusiones Referencias", " FOG Computing Robin Armando Salvatierra Bautista abr568@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: IOT, Big Data, Nube, Dispositivo, Niebla, datos, red, latencia, seguridad. Tomando la nube como punto de partida en la actualidad todos los involucrados en el campo de la informática conocen bien la importancia de sacar provecho de grandes volúmenes de información, están relacionados términos como Big Data y Bussiness Intelligence donde el proceso de la recolección de datos, analizarlos y generar reportes es un punto clave dentro de las empresas que marcan la diferencia entre una exitosa y una que no explota y aprovecha tales ventajas. En base a la necesidad de analizar cada vez más información el término IOT es una realidad que se refleja cada vez más debido al gran crecimiento de dispositivos conectados a la red, desde una computadora hasta un SmartWatch. Con la previa de la importancia de la nube y el auge que toma el IOT se menciona un crecimiento debido a las nuevas tecnologías como las que ofrece Amazon con Echo Show y sus alternativas de Google y Apple; estos altavoces inteligentes ofrecen la solución para lograr incorporar dispositivos domésticos inteligentes harán posible una proyección de dispositivos conectados. Dentro de esta perspectiva la firma Gartner ha proyectado algunas predicciones sobre el ritmo de adopción de esta tecnología, pronosticando que para el año 2020 habrá 20,8 mil millones de dispositivos conectados ya directamente al Internet de las Cosas. Dispositivos que van a involucrar carros autónomos, drones, robots industriales, transmisión de video 4K y todo aquello que involucre una Smart City así como también nuevas tecnologías dan lugar a un crecimiento de tráfico de datos que provienen de internet para lugares centralizados que se encargan de procesar, esto provoca un desafío para la nube debido a la latencia que se generaría a partir de la gran demanda de datos haciendo necesario más ancho de banda y más tiempo. Debido a este nuevo desafío donde Big Data y el IOT generan gran aumento en la información y se acumulan en los bordes de la red donde son transmitidos a centros de datos, lugares centralizados de la nube. ¿Qué es Fog Computing? Es un término creado por CISCO para dar una solución al problema antes expuesto, donde el proceso de análisis de datos se realiza en el borde de la red atacando directamente el problema y evitando hacer un recorrido hasta un centro de datos. Fog Computing creado para trabajar con el crecimiento que demanda el IOT, consiste en una descentralización del procesamiento de datos y trabajar con nodos que estén al borde de donde se generan los datos para evitar así el paso por la nube. En otras palabras permite a los dispositivos que producen datos sean procesados más cerca de donde son creados en vez de ser enviados por medio de largas distancias para que lleguen a centros de datos (la nube). CISCO propone que parte del procesamiento de datos tendría al borde o frontera de la red, utilizando dispositivos tal como un router, conmutador y dispositivos de acceso integrado, dispositivos que serán nodos dentro de una red de área local (LAN) cerca de los dispositivos que generan datos y que se conectan con una red de área extensa externa (WAN). Que sucede del lado de Fog Computing Recibir feeds desde dispositivos usando cualquier protocolo en tiempo real. Ejecutar aplicaciones habilitadas para IOT que buscan el control y análisis en tiempo real, con un tiempo de respuesta de milisegundos. Proporcionar almacenamiento transitorio, a menudo 1-2 horas. Enviar resúmenes de datos periódicos a la nube. Que sucede en la nube Recibe y agrega resúmenes de datos de muchos nodos de la niebla. Realiza el análisis sobre datos de IOT y datos de otras fuentes. Puede reconfigurar reglas de aplicación a los nodos. Cabe mencionar que el termino edge computing hace referencia a la solución de que cada dispositivo sea capaz de procesar y analizar los datos localmente, es un acercamiento a Fog Computing pero centrándose más en los dispositivos finales. Es por ello que algunos autores usan el termino como una solución distinta a Fog computing y otros autores lo ven como un mismo modelo dándole el termino edge a los billones de dispositivos finales dentro de una pirámide donde cada dispositivo final (edge) procesan y dan soluciones, que son transferidos a los millones de nodos (fog) para ser procesados en los miles de servidores en la nube (cloud). Los beneficios que ofrece Latencia: Este modelo tiene como resultado minimizar la latencia a partir de procesar los datos en una capa intermedia entre los dispositivos finales y la nube generando información de manera inmediata para toma de decisiones. Agilidad empresarial: Los desarrolladores pueden crear de manera eficaz aplicaciones para la niebla e implementar donde se requiera. Seguridad: Se pueden proteger los nodos utilizando los mismos controles y procedimientos de seguridad en una red. Control de privacidad: Analizar datos confidenciales de manera local en vez de enviarlos a la nube, pudiendo controlar los dispositivos que reciben, analizan y almacenan datos. Menor gasto en ancho de banda: Se conserva el ancho de banda en la red procesando los datos de forma local para su análisis. Conclusiones El cambio que se genera a partir del auge que toma IOT que consiste en el crecimiento exponencial de datos a procesar se debe afrontar de forma estratégica para evitar latencia en los servicios prestados. Fog Computing ofrece una expansión de la nube estableciendo nodos al borde de la red capaces de analizar y enviar respuestas a peticiones, conservando un la capacidad de enviar resumen a la nube. Es importante conocer nuevas metodologías que afrontan el crecimiento continuo del internet en cuando a las nuevas tendencias y la importancia del procesamiento de datos masivos. Referencias [1] York Perry, «FayerWayer», En 2020 habrá 20 mil millones de dispositivos conectados al Internet de las Cosas, 12 noviembre 2015. [En línea]. Disponible en: https://bit.ly/2UZmnM8. [Último acceso: 14 febrero 2018]. [2] Norberto Figuerola, «ArticuloSit», ¿Qué es Fog o Edge computing ?, 26 septiembre 2014. [En línea]. Disponible en: https://bit.ly/36dmE0l. [Último acceso: 14 febrero 2018]. [3] Maher Abdelshkour, «CISCO», IoT, from Cloud to Fog Computing, 25 marzo 2015. [En línea]. Disponible en: https://bit.ly/2UXmisj. [Último acceso: 14 febrero 2018]. [4] «CISCO», Fog Computing and the Internet of Things: Extend the Cloud to Where the Things Are, 2015. [En línea]. Disponible en: https://bit.ly/3hxvoUp. [Último acceso: 14 febrero 2018]. [5] «Moxa», Should You Consider Fog Computing for Your IIoT?, 7 noviembre 2017. [En línea]. Disponible en: https://bit.ly/36eRLJ6. [Último acceso: 14 febrero 2018]. [6] «Nobbot», Por qué si aprendiste a manejarte en la nube (cloud), ahora tendrás que hacerlo en la niebla (fog computing), 13 julio 2016. [En línea]. Disponible en: https://bit.ly/3hgZ35h. [Último acceso: 14 febrero 2018]. [7] «Nobbot», Por qué si aprendiste a manejarte en la nube (cloud), ahora tendrás que hacerlo en la niebla (fog computing), 13 julio 2016. [En línea]. Disponible en: https://bit.ly/3hgZ35h. [Último acceso: 14 febrero 2018]. "],["09-dprera.html", "Amazon Alexa y su conquista del mercado de los asistentes inteligentes No fue el primer asistente inteligente. Amazon Echo, su altavoz inteligente Los Skills, gran parte del atractivo de Alexa Ningún software es perfecto Una competencia más interesada en los asistentes inteligentes Conclusiones Referencias", " Amazon Alexa y su conquista del mercado de los asistentes inteligentes Diego José Prera djprera@gmail.com Estudiante de Ingeniería en Ciencias y Sistemas - USAC Palabras Clave: Tecnología, asistente inteligente, Amazon, Alexa, Echo. Cuando se piensa en Amazon, se piensa normalmente en su tienda en linea, pero es solo una parte del gigante que es. Esta empresa estadounidense se ha convertido en una de las compañías más importantes de tecnología por distintas razones. Además de su famosa tienda indicada anteriormente, es el proveedor más grande de infraestructura en la nube, además de producir sus propios dispositivos electrónicos (Kindle, Amazon Echo, Fire TV, entre otros) y su propio ecosistema de venta de libros digitales, video y música. Pero un dispositivo ha llamado la atención en los últimos años: Amazon Echo y su asistente de voz inteligente Alexa. Imagen 1: Amazon Alexa Fuente: Wikipedia No fue el primer asistente inteligente. Antes de Alexa, ya existían otros asistentes inteligentes. El más relevante era Siri de Apple, el asistente que fue integrado a sus dispositivos iOS. Luego Google introdujo Google Now, que podía ser usado en Android, IOS, Chrome OS y hasta en Google Chrome, su navegador web. Tanto Siri como Google Now (que posteriormente fuera reemplazado por Google Assistant), lograban ofrecer sistemas de reconocimiento de voz poderosos, pero normalmente solo disponibles en smartphones, tablets y computadoras. Amazon no tenía un ecosistema tan bueno como estos gigantes de la tecnología, por lo que lanzar su asistente a los mismos dispositivos utilizados por Siri y Google Now hubiera sido un suicidio. Amazon Echo, su altavoz inteligente Por tal motivo crearon Amazon Echo, un altavoz 100% dedicado al uso del asistente. Este se encuentra escuchando hasta ser accionado al decir Alexa (aunque puede configurarse para utilizar otra palabra). Luego el usuario podrá indicarle a Alexa lo que quiere que haga por medio de instrucciones, para luego ser respondido por el propio asistente. Es un dispositivo independiente y solamente se utiliza otro dispositivo para configuraciones específicas que sean muy complicadas de hacer por medio de voz. Echo fue un éxito. A las personas les encanto la idea de tener un dispositivo dedicado y que esté siempre disponible sin necesidad de tener que interactuar con una pantalla o teclado. Echo fue evolucionando y actualmente se venden distintos modelos: Echo Dot, Echo Spot, Echo Show son algunos de ellos. Según datos de Strategy Analytics, Amazon tendría el 70% del mercado de los altavoces inteligentes para el final de 2017. Y aunque son cifras muy buenas, Amazon no quiere que su sistema sea exclusivamente para altavoces. Amazon quiso ir más allá y comenzó a permitir que se implementará su asistente a la mayor cantidad de dispositivos posibles, como teléfonos inteligentes, automóviles, refrigeradores, incluso hasta en cargadores para carros. Incluso ha permitido que otros fabricantes puedan crear altavoces con Alexa similares a Echo. El fin de Amazon es el de convertir su sistema en el Android de los asistentes inteligentes. Imagen 2: Amazon Echo family Fuente: Amazon Los Skills, gran parte del atractivo de Alexa Gran parte del éxito que han tenido es por las posibilidades que posee Alexa, el sistema que quiere Amazon que sea el centro de todos los dispositivos. El asistente permite al usuario realizar varias actividades: reproducir música de servicios de streaming (Spotify, Pandora, Amazon Prime Music), resolver preguntas, escuchar noticias de múltiples fuentes, hacer llamadas, mandar y recibir mensajes, hacer pedidos a restaurantes, comprar productos en Amazon, entre muchas otras cosas más. Amazon además ha proporcionado a los desarrolladores de herramientas para poder diseñar tus propias acciones de Alexa, los Skills. Los Skills son uno de los puntos clave por el cual el asistente se ha vuelto tan popular. Estos permiten expandir las funcionalidades de asistente según lo desee un fabricante o desarrollador mediante el Alexa Skills Kit, el SDK que proporciona Amazon. Actualmente existen una gran variedad de Skills que van desde pedir comida a restaurantes (Dominos es el más conocido), jugar Jeopardi, controlar luces o termostatos, conexión a servicios de Google como Calendar, conocer el estado de cuenta en un banco, incluso hacer experimentos con Arduino; el potencial del asistente es enorme. Ningún software es perfecto No todo es perfecto y Alexa posee algunas deficiencias. Primero, solo se encuentra disponible en inglés, alemán y japonés. Esto le impide tener un alcance más global, especialmente en latinoamérica. El soporte de múltiples lenguajes es algo que Amazon tiene que implementar si quiere tener más presencia en varios países. Otro problema es que Alexa no es tan inteligente como su competencia más directa, Google Assistant. A pesar de que Amazon ha mejorado mucho su asistente, este posee deficiencias a la hora de interpretar ciertas preguntas, muchas de ellas resultando con un mensaje de error. Google Assistant es más completo en este sentido y sabe hasta mantener el contexto cuando se realizan preguntas relacionadas. Una competencia más interesada en los asistentes inteligentes A pesar de sus defectos, Alexa logró darle mayor relevancia a los asistentes inteligentes. Esto provocó que la competencia empezará a mirar con nuevos ojos las posibilidades de estos. Google con su Google Assistant, es la principal competencia que tiene Amazon en este mercado. Google ha tratado de extender también el uso de su asistente y recientemente sacó al mercado Google Home, un altavoz similar al Echo de Amazon. También está Cortana de Microsoft. Que venga de serie en el sistema operativo Windows 10, uno de los OS más utilizados en el mundo de las computadoras personales, lo convierte en un competidor a tomar en cuenta. Por otro lado tenemos a Siri de Apple. Lo han ido mejorando constantemente, y recientemente sacaron HomePod, su propio altavoz inteligente e integrado fuertemente al gran ecosistema que tiene Apple. Hasta Samsung creó su propio asistente, Bixby. No ha tenido mucho éxito en sus teléfonos inteligentes, pero la empresa apuesta por él y planea integrarlo a otros dispositivos de la marca, como televisores y refrigeradores. Amazon ha logrado darle un papel más importante a los asistentes inteligentes con Alexa. Gracias a su visión y a la inversión constante al proyecto, han logrado llevar al asistente hacía donde está ahora. Solo el futuro dirá si Alexa se mantiene vigente, pero el buen trabajo de Amazon permite ver un futuro prometedor para su asistente virtual. Conclusiones Alexa es un asistente de inteligente con mucho potencial, tanto por su implementación en múltiples dispositivos como la capacidad de sus Skills. Amazon ha sabido popularizar su dispositivo en Estados Unidos, pero en algún momento va a ser necesaria su expansión a otras regiones del mundo, lo que va a requerir el soporte para varios idiomas. La competencia se ha vuelto cada vez más dura, siendo Google Assistant el principal competidor que tiene Alexa. Mejorar constantemente su asistente es prioridad para Amazon si se quiere una mayor expansión del asistente. Referencias [1] Ron Miller, «Tech Crunch», AWS continues to rule the cloud infrastructure market , 30 noviembre 2017. [En línea]. Disponible en: https://tcrn.ch/3jIB9Bj. [Último acceso: 13 febrero 2018]. [2] Todd Haselton, «CNBC», Amazon is winning the smart home speaker wars by a huge margin, 12 noviembre 2017. [En línea]. Disponible en: https://tcrn.ch/3jIB9Bj. [Último acceso: 13 febrero 2018]. [3] Jordan Palmer, «Android Police», Amazon is winning the smart home speaker wars by a huge margin, 31 enero 2018. [En línea]. Disponible en: https://bit.ly/2V7HagK. [Último acceso: 13 febrero 2018]. [4] Richard Gao, «Android Police», Ultimate Ears $229.99 BLAST and $299.99 MEGABLAST bring WiFi, Alexa integration, and improved sound, 19 noviembre 2017. [En línea]. Disponible en: https://bit.ly/3ytMxFv. [Último acceso: 14 febrero 2018]. [5] Taylor Martin, «Cnet», 50 most useful Alexa skills, 29 enero 2018. [En línea]. Disponible en: https://cnet.co/3jWPxWX. [Último acceso: 14 febrero 2018]. [6] Glenn Cameron, «Amazon», Announcing the Alexa and Arduino Smart Home Challenge on Hackster.io, 21 noviembre 2017. [En línea]. Disponible en: https://amzn.to/3jJMYY4. [Último acceso: 14 febrero 2018]. [7] Andrew Williams, «Trusted Reviews», Google Assistant vs Amazon Alexa: Whats the best digital assistant in 2018?, 17 enero 2018. [En línea]. Disponible en: https://bit.ly/3yj6BtO4. [Último acceso: 14 febrero 2018]. [8] Shu On Kwok, «Next Pit», Will Bixbys failed Galaxy S8 launch have far-reaching consequences?, 12 julio 2017. [En línea]. Disponible en: https://bit.ly/3Ar6hv3. [Último acceso: 14 febrero 2018]. [9] Rik Henderson, «Pcket Lint», Samsung Family Hub smart fridge adds Bixby and SmartThings control for 2018, 8 enero 2018. [En línea]. Disponible en: https://bit.ly/3jJhr8z. [Último acceso: 14 febrero 2018]. "]]
